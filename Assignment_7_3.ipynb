{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403A52L07/Generative-AI/blob/main/Assignment_7_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"/content/diabetes.csv\") # Change to your dataset\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = data.iloc[:, :-1].values # All columns except the last\n",
        "y = data.iloc[:, -1].values # Last column (target)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Save the scaler for future use\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# Define the ANN model\n",
        "model = Sequential([\n",
        "    Dense(12, activation=\"swish\", input_shape=(X_train.shape[1],)),\n",
        "    Dense(25, activation=\"swish\"),\n",
        "    Dense(15, activation=\"swish\"),\n",
        "    Dense(1, activation=\"sigmoid\") # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adagrad(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Predict classes\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=[\"Non-Diabetic\", \"Diabetic\"])\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(report)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Diabetic\", \"Diabetic\"],\n",
        "            yticklabels=[\"Non-Diabetic\", \"Diabetic\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"diabetes_ann_model.h5\")\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "# Load the trained model and scaler\n",
        "def load_trained_model():\n",
        "    return load_model(\"diabetes_ann_model.h5\"), joblib.load(\"scaler.pkl\")\n",
        "\n",
        "# Predict function\n",
        "def predict_diabetes(input_data):\n",
        "    model, scaler = load_trained_model()\n",
        "    input_array = np.array(input_data).reshape(1, -1)\n",
        "    input_scaled = scaler.transform(input_array)\n",
        "    prediction = model.predict(input_scaled)\n",
        "    return \"Diabetic\" if prediction > 0.5 else \"Non-Diabetic\"\n",
        "\n",
        "# Example input\n",
        "sample_input = [6, 148, 72, 35, 0, 33.6, 0.627, 50] # Replace with real data\n",
        "result = predict_diabetes(sample_input)\n",
        "print(f\"Prediction: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SsGDH2a6ajy_",
        "outputId": "714dc54e-0c7a-433c-c516-94abfee03518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.5119 - loss: 0.6961 - val_accuracy: 0.5325 - val_loss: 0.6976\n",
            "Epoch 2/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5358 - loss: 0.6970 - val_accuracy: 0.5649 - val_loss: 0.6945\n",
            "Epoch 3/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5620 - loss: 0.6914 - val_accuracy: 0.5844 - val_loss: 0.6919\n",
            "Epoch 4/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5943 - loss: 0.6969 - val_accuracy: 0.6104 - val_loss: 0.6896\n",
            "Epoch 5/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6383 - loss: 0.6901 - val_accuracy: 0.6234 - val_loss: 0.6874\n",
            "Epoch 6/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6326 - loss: 0.6877 - val_accuracy: 0.6494 - val_loss: 0.6855\n",
            "Epoch 7/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6518 - loss: 0.6846 - val_accuracy: 0.6299 - val_loss: 0.6836\n",
            "Epoch 8/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7005 - loss: 0.6800 - val_accuracy: 0.6364 - val_loss: 0.6820\n",
            "Epoch 9/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6783 - loss: 0.6780 - val_accuracy: 0.6364 - val_loss: 0.6803\n",
            "Epoch 10/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6993 - loss: 0.6755 - val_accuracy: 0.6429 - val_loss: 0.6788\n",
            "Epoch 11/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6999 - loss: 0.6754 - val_accuracy: 0.6623 - val_loss: 0.6773\n",
            "Epoch 12/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6647 - loss: 0.6796 - val_accuracy: 0.6818 - val_loss: 0.6758\n",
            "Epoch 13/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6918 - loss: 0.6735 - val_accuracy: 0.6883 - val_loss: 0.6745\n",
            "Epoch 14/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7021 - loss: 0.6747 - val_accuracy: 0.6818 - val_loss: 0.6732\n",
            "Epoch 15/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7185 - loss: 0.6708 - val_accuracy: 0.6883 - val_loss: 0.6719\n",
            "Epoch 16/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6843 - loss: 0.6773 - val_accuracy: 0.6883 - val_loss: 0.6707\n",
            "Epoch 17/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7044 - loss: 0.6682 - val_accuracy: 0.7013 - val_loss: 0.6695\n",
            "Epoch 18/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7216 - loss: 0.6681 - val_accuracy: 0.6948 - val_loss: 0.6683\n",
            "Epoch 19/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6968 - loss: 0.6698 - val_accuracy: 0.6948 - val_loss: 0.6672\n",
            "Epoch 20/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7079 - loss: 0.6658 - val_accuracy: 0.6948 - val_loss: 0.6660\n",
            "Epoch 21/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.6680 - val_accuracy: 0.6948 - val_loss: 0.6649\n",
            "Epoch 22/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7006 - loss: 0.6654 - val_accuracy: 0.6948 - val_loss: 0.6639\n",
            "Epoch 23/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7010 - loss: 0.6614 - val_accuracy: 0.7078 - val_loss: 0.6628\n",
            "Epoch 24/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7027 - loss: 0.6609 - val_accuracy: 0.7078 - val_loss: 0.6618\n",
            "Epoch 25/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6878 - loss: 0.6632 - val_accuracy: 0.7078 - val_loss: 0.6607\n",
            "Epoch 26/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7223 - loss: 0.6531 - val_accuracy: 0.7078 - val_loss: 0.6597\n",
            "Epoch 27/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 0.6575 - val_accuracy: 0.7078 - val_loss: 0.6587\n",
            "Epoch 28/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 0.6608 - val_accuracy: 0.7078 - val_loss: 0.6577\n",
            "Epoch 29/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7086 - loss: 0.6535 - val_accuracy: 0.7078 - val_loss: 0.6568\n",
            "Epoch 30/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.6570 - val_accuracy: 0.7078 - val_loss: 0.6559\n",
            "Epoch 31/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.6586 - val_accuracy: 0.7143 - val_loss: 0.6549\n",
            "Epoch 32/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7198 - loss: 0.6543 - val_accuracy: 0.7143 - val_loss: 0.6540\n",
            "Epoch 33/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7025 - loss: 0.6546 - val_accuracy: 0.7273 - val_loss: 0.6531\n",
            "Epoch 34/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7083 - loss: 0.6579 - val_accuracy: 0.7403 - val_loss: 0.6522\n",
            "Epoch 35/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7140 - loss: 0.6528 - val_accuracy: 0.7338 - val_loss: 0.6513\n",
            "Epoch 36/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7064 - loss: 0.6534 - val_accuracy: 0.7338 - val_loss: 0.6504\n",
            "Epoch 37/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7057 - loss: 0.6534 - val_accuracy: 0.7338 - val_loss: 0.6495\n",
            "Epoch 38/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7359 - loss: 0.6491 - val_accuracy: 0.7273 - val_loss: 0.6486\n",
            "Epoch 39/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7159 - loss: 0.6482 - val_accuracy: 0.7273 - val_loss: 0.6477\n",
            "Epoch 40/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7194 - loss: 0.6483 - val_accuracy: 0.7208 - val_loss: 0.6469\n",
            "Epoch 41/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6904 - loss: 0.6548 - val_accuracy: 0.7208 - val_loss: 0.6460\n",
            "Epoch 42/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6990 - loss: 0.6470 - val_accuracy: 0.7208 - val_loss: 0.6452\n",
            "Epoch 43/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7244 - loss: 0.6440 - val_accuracy: 0.7208 - val_loss: 0.6443\n",
            "Epoch 44/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7002 - loss: 0.6484 - val_accuracy: 0.7143 - val_loss: 0.6435\n",
            "Epoch 45/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7246 - loss: 0.6410 - val_accuracy: 0.7143 - val_loss: 0.6426\n",
            "Epoch 46/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7073 - loss: 0.6474 - val_accuracy: 0.7208 - val_loss: 0.6418\n",
            "Epoch 47/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7039 - loss: 0.6479 - val_accuracy: 0.7208 - val_loss: 0.6409\n",
            "Epoch 48/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7155 - loss: 0.6428 - val_accuracy: 0.7143 - val_loss: 0.6402\n",
            "Epoch 49/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7120 - loss: 0.6426 - val_accuracy: 0.7273 - val_loss: 0.6393\n",
            "Epoch 50/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7276 - loss: 0.6398 - val_accuracy: 0.7273 - val_loss: 0.6385\n",
            "Epoch 51/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6986 - loss: 0.6406 - val_accuracy: 0.7208 - val_loss: 0.6377\n",
            "Epoch 52/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7245 - loss: 0.6380 - val_accuracy: 0.7273 - val_loss: 0.6369\n",
            "Epoch 53/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7075 - loss: 0.6413 - val_accuracy: 0.7273 - val_loss: 0.6361\n",
            "Epoch 54/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7086 - loss: 0.6417 - val_accuracy: 0.7273 - val_loss: 0.6353\n",
            "Epoch 55/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7259 - loss: 0.6353 - val_accuracy: 0.7273 - val_loss: 0.6345\n",
            "Epoch 56/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.6348 - val_accuracy: 0.7273 - val_loss: 0.6337\n",
            "Epoch 57/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7590 - loss: 0.6276 - val_accuracy: 0.7338 - val_loss: 0.6329\n",
            "Epoch 58/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.6336 - val_accuracy: 0.7338 - val_loss: 0.6321\n",
            "Epoch 59/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7356 - loss: 0.6237 - val_accuracy: 0.7338 - val_loss: 0.6313\n",
            "Epoch 60/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7398 - loss: 0.6329 - val_accuracy: 0.7338 - val_loss: 0.6305\n",
            "Epoch 61/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7201 - loss: 0.6336 - val_accuracy: 0.7403 - val_loss: 0.6298\n",
            "Epoch 62/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7276 - loss: 0.6267 - val_accuracy: 0.7403 - val_loss: 0.6290\n",
            "Epoch 63/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7083 - loss: 0.6345 - val_accuracy: 0.7403 - val_loss: 0.6282\n",
            "Epoch 64/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7068 - loss: 0.6319 - val_accuracy: 0.7403 - val_loss: 0.6274\n",
            "Epoch 65/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7061 - loss: 0.6384 - val_accuracy: 0.7403 - val_loss: 0.6266\n",
            "Epoch 66/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7083 - loss: 0.6367 - val_accuracy: 0.7403 - val_loss: 0.6258\n",
            "Epoch 67/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6879 - loss: 0.6334 - val_accuracy: 0.7403 - val_loss: 0.6250\n",
            "Epoch 68/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7158 - loss: 0.6297 - val_accuracy: 0.7403 - val_loss: 0.6243\n",
            "Epoch 69/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7102 - loss: 0.6322 - val_accuracy: 0.7403 - val_loss: 0.6235\n",
            "Epoch 70/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7381 - loss: 0.6211 - val_accuracy: 0.7403 - val_loss: 0.6227\n",
            "Epoch 71/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7322 - loss: 0.6221 - val_accuracy: 0.7403 - val_loss: 0.6220\n",
            "Epoch 72/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 0.6223 - val_accuracy: 0.7403 - val_loss: 0.6212\n",
            "Epoch 73/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7243 - loss: 0.6271 - val_accuracy: 0.7403 - val_loss: 0.6204\n",
            "Epoch 74/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 0.6266 - val_accuracy: 0.7338 - val_loss: 0.6196\n",
            "Epoch 75/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.6290 - val_accuracy: 0.7338 - val_loss: 0.6189\n",
            "Epoch 76/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7187 - loss: 0.6221 - val_accuracy: 0.7338 - val_loss: 0.6181\n",
            "Epoch 77/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7518 - loss: 0.6095 - val_accuracy: 0.7338 - val_loss: 0.6174\n",
            "Epoch 78/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7536 - loss: 0.6100 - val_accuracy: 0.7338 - val_loss: 0.6167\n",
            "Epoch 79/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7344 - loss: 0.6197 - val_accuracy: 0.7338 - val_loss: 0.6159\n",
            "Epoch 80/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7250 - loss: 0.6170 - val_accuracy: 0.7403 - val_loss: 0.6151\n",
            "Epoch 81/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7647 - loss: 0.6069 - val_accuracy: 0.7403 - val_loss: 0.6144\n",
            "Epoch 82/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7587 - loss: 0.6178 - val_accuracy: 0.7403 - val_loss: 0.6137\n",
            "Epoch 83/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7277 - loss: 0.6116 - val_accuracy: 0.7403 - val_loss: 0.6129\n",
            "Epoch 84/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7093 - loss: 0.6232 - val_accuracy: 0.7403 - val_loss: 0.6122\n",
            "Epoch 85/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7213 - loss: 0.6188 - val_accuracy: 0.7403 - val_loss: 0.6114\n",
            "Epoch 86/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7027 - loss: 0.6224 - val_accuracy: 0.7403 - val_loss: 0.6107\n",
            "Epoch 87/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7272 - loss: 0.6163 - val_accuracy: 0.7403 - val_loss: 0.6099\n",
            "Epoch 88/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7136 - loss: 0.6237 - val_accuracy: 0.7403 - val_loss: 0.6092\n",
            "Epoch 89/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7153 - loss: 0.6147 - val_accuracy: 0.7403 - val_loss: 0.6085\n",
            "Epoch 90/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7028 - loss: 0.6171 - val_accuracy: 0.7403 - val_loss: 0.6077\n",
            "Epoch 91/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7168 - loss: 0.6150 - val_accuracy: 0.7403 - val_loss: 0.6070\n",
            "Epoch 92/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7337 - loss: 0.6037 - val_accuracy: 0.7403 - val_loss: 0.6063\n",
            "Epoch 93/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7096 - loss: 0.6174 - val_accuracy: 0.7403 - val_loss: 0.6056\n",
            "Epoch 94/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7462 - loss: 0.6050 - val_accuracy: 0.7403 - val_loss: 0.6049\n",
            "Epoch 95/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7272 - loss: 0.6008 - val_accuracy: 0.7403 - val_loss: 0.6042\n",
            "Epoch 96/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7709 - loss: 0.5975 - val_accuracy: 0.7338 - val_loss: 0.6035\n",
            "Epoch 97/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.6041 - val_accuracy: 0.7338 - val_loss: 0.6027\n",
            "Epoch 98/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.5969 - val_accuracy: 0.7338 - val_loss: 0.6021\n",
            "Epoch 99/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7422 - loss: 0.6072 - val_accuracy: 0.7338 - val_loss: 0.6014\n",
            "Epoch 100/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7294 - loss: 0.6059 - val_accuracy: 0.7273 - val_loss: 0.6007\n",
            "Epoch 101/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7198 - loss: 0.6064 - val_accuracy: 0.7273 - val_loss: 0.5999\n",
            "Epoch 102/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7237 - loss: 0.6147 - val_accuracy: 0.7273 - val_loss: 0.5992\n",
            "Epoch 103/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.6098 - val_accuracy: 0.7273 - val_loss: 0.5985\n",
            "Epoch 104/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7329 - loss: 0.6046 - val_accuracy: 0.7273 - val_loss: 0.5978\n",
            "Epoch 105/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 0.5973 - val_accuracy: 0.7273 - val_loss: 0.5972\n",
            "Epoch 106/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7512 - loss: 0.6026 - val_accuracy: 0.7273 - val_loss: 0.5965\n",
            "Epoch 107/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7699 - loss: 0.5940 - val_accuracy: 0.7273 - val_loss: 0.5958\n",
            "Epoch 108/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.5915 - val_accuracy: 0.7338 - val_loss: 0.5951\n",
            "Epoch 109/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7203 - loss: 0.6085 - val_accuracy: 0.7338 - val_loss: 0.5944\n",
            "Epoch 110/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7299 - loss: 0.6094 - val_accuracy: 0.7403 - val_loss: 0.5938\n",
            "Epoch 111/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7401 - loss: 0.6030 - val_accuracy: 0.7403 - val_loss: 0.5931\n",
            "Epoch 112/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7407 - loss: 0.5948 - val_accuracy: 0.7403 - val_loss: 0.5924\n",
            "Epoch 113/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7386 - loss: 0.5912 - val_accuracy: 0.7403 - val_loss: 0.5917\n",
            "Epoch 114/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.6026 - val_accuracy: 0.7403 - val_loss: 0.5911\n",
            "Epoch 115/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7655 - loss: 0.5872 - val_accuracy: 0.7403 - val_loss: 0.5904\n",
            "Epoch 116/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7216 - loss: 0.5989 - val_accuracy: 0.7403 - val_loss: 0.5897\n",
            "Epoch 117/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.5889 - val_accuracy: 0.7403 - val_loss: 0.5891\n",
            "Epoch 118/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7366 - loss: 0.6012 - val_accuracy: 0.7468 - val_loss: 0.5885\n",
            "Epoch 119/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7415 - loss: 0.5969 - val_accuracy: 0.7468 - val_loss: 0.5878\n",
            "Epoch 120/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7376 - loss: 0.5876 - val_accuracy: 0.7468 - val_loss: 0.5871\n",
            "Epoch 121/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7542 - loss: 0.5937 - val_accuracy: 0.7468 - val_loss: 0.5865\n",
            "Epoch 122/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.5960 - val_accuracy: 0.7468 - val_loss: 0.5859\n",
            "Epoch 123/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7402 - loss: 0.5869 - val_accuracy: 0.7468 - val_loss: 0.5852\n",
            "Epoch 124/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7413 - loss: 0.5905 - val_accuracy: 0.7468 - val_loss: 0.5846\n",
            "Epoch 125/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7339 - loss: 0.5937 - val_accuracy: 0.7468 - val_loss: 0.5840\n",
            "Epoch 126/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7634 - loss: 0.5768 - val_accuracy: 0.7468 - val_loss: 0.5833\n",
            "Epoch 127/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7311 - loss: 0.5931 - val_accuracy: 0.7468 - val_loss: 0.5827\n",
            "Epoch 128/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7494 - loss: 0.5811 - val_accuracy: 0.7532 - val_loss: 0.5821\n",
            "Epoch 129/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7375 - loss: 0.5891 - val_accuracy: 0.7597 - val_loss: 0.5814\n",
            "Epoch 130/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7405 - loss: 0.6001 - val_accuracy: 0.7597 - val_loss: 0.5808\n",
            "Epoch 131/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7482 - loss: 0.5876 - val_accuracy: 0.7597 - val_loss: 0.5802\n",
            "Epoch 132/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7251 - loss: 0.5921 - val_accuracy: 0.7597 - val_loss: 0.5796\n",
            "Epoch 133/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7621 - loss: 0.5773 - val_accuracy: 0.7597 - val_loss: 0.5790\n",
            "Epoch 134/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7366 - loss: 0.5814 - val_accuracy: 0.7597 - val_loss: 0.5784\n",
            "Epoch 135/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7393 - loss: 0.5846 - val_accuracy: 0.7597 - val_loss: 0.5778\n",
            "Epoch 136/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7151 - loss: 0.5947 - val_accuracy: 0.7597 - val_loss: 0.5772\n",
            "Epoch 137/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7295 - loss: 0.5888 - val_accuracy: 0.7597 - val_loss: 0.5766\n",
            "Epoch 138/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7632 - loss: 0.5771 - val_accuracy: 0.7597 - val_loss: 0.5760\n",
            "Epoch 139/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7238 - loss: 0.5866 - val_accuracy: 0.7597 - val_loss: 0.5754\n",
            "Epoch 140/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7241 - loss: 0.5928 - val_accuracy: 0.7597 - val_loss: 0.5748\n",
            "Epoch 141/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7686 - loss: 0.5669 - val_accuracy: 0.7662 - val_loss: 0.5742\n",
            "Epoch 142/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 0.5804 - val_accuracy: 0.7662 - val_loss: 0.5736\n",
            "Epoch 143/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7392 - loss: 0.5723 - val_accuracy: 0.7662 - val_loss: 0.5730\n",
            "Epoch 144/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.5847 - val_accuracy: 0.7662 - val_loss: 0.5725\n",
            "Epoch 145/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7376 - loss: 0.5807 - val_accuracy: 0.7662 - val_loss: 0.5719\n",
            "Epoch 146/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7260 - loss: 0.5675 - val_accuracy: 0.7662 - val_loss: 0.5713\n",
            "Epoch 147/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 0.5768 - val_accuracy: 0.7727 - val_loss: 0.5708\n",
            "Epoch 148/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7326 - loss: 0.5797 - val_accuracy: 0.7727 - val_loss: 0.5702\n",
            "Epoch 149/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7706 - loss: 0.5678 - val_accuracy: 0.7727 - val_loss: 0.5697\n",
            "Epoch 150/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7362 - loss: 0.5866 - val_accuracy: 0.7727 - val_loss: 0.5691\n",
            "Epoch 151/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7559 - loss: 0.5753 - val_accuracy: 0.7727 - val_loss: 0.5685\n",
            "Epoch 152/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7556 - loss: 0.5709 - val_accuracy: 0.7727 - val_loss: 0.5680\n",
            "Epoch 153/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.5710 - val_accuracy: 0.7727 - val_loss: 0.5674\n",
            "Epoch 154/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7354 - loss: 0.5792 - val_accuracy: 0.7727 - val_loss: 0.5669\n",
            "Epoch 155/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7240 - loss: 0.5775 - val_accuracy: 0.7727 - val_loss: 0.5663\n",
            "Epoch 156/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7585 - loss: 0.5653 - val_accuracy: 0.7727 - val_loss: 0.5658\n",
            "Epoch 157/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 0.5769 - val_accuracy: 0.7727 - val_loss: 0.5653\n",
            "Epoch 158/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.5798 - val_accuracy: 0.7727 - val_loss: 0.5648\n",
            "Epoch 159/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.5729 - val_accuracy: 0.7662 - val_loss: 0.5642\n",
            "Epoch 160/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7281 - loss: 0.5801 - val_accuracy: 0.7662 - val_loss: 0.5637\n",
            "Epoch 161/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 0.5816 - val_accuracy: 0.7662 - val_loss: 0.5632\n",
            "Epoch 162/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.5906 - val_accuracy: 0.7662 - val_loss: 0.5627\n",
            "Epoch 163/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7271 - loss: 0.5930 - val_accuracy: 0.7662 - val_loss: 0.5621\n",
            "Epoch 164/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7170 - loss: 0.5825 - val_accuracy: 0.7662 - val_loss: 0.5616\n",
            "Epoch 165/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.5665 - val_accuracy: 0.7662 - val_loss: 0.5611\n",
            "Epoch 166/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.5561 - val_accuracy: 0.7662 - val_loss: 0.5606\n",
            "Epoch 167/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 0.5753 - val_accuracy: 0.7662 - val_loss: 0.5601\n",
            "Epoch 168/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7194 - loss: 0.5948 - val_accuracy: 0.7662 - val_loss: 0.5596\n",
            "Epoch 169/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.5602 - val_accuracy: 0.7662 - val_loss: 0.5591\n",
            "Epoch 170/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7724 - loss: 0.5507 - val_accuracy: 0.7662 - val_loss: 0.5586\n",
            "Epoch 171/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.5726 - val_accuracy: 0.7662 - val_loss: 0.5581\n",
            "Epoch 172/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.5528 - val_accuracy: 0.7662 - val_loss: 0.5576\n",
            "Epoch 173/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7525 - loss: 0.5682 - val_accuracy: 0.7662 - val_loss: 0.5572\n",
            "Epoch 174/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7388 - loss: 0.5597 - val_accuracy: 0.7662 - val_loss: 0.5567\n",
            "Epoch 175/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7469 - loss: 0.5846 - val_accuracy: 0.7662 - val_loss: 0.5562\n",
            "Epoch 176/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7619 - loss: 0.5566 - val_accuracy: 0.7662 - val_loss: 0.5558\n",
            "Epoch 177/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7409 - loss: 0.5679 - val_accuracy: 0.7662 - val_loss: 0.5553\n",
            "Epoch 178/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 0.5606 - val_accuracy: 0.7662 - val_loss: 0.5548\n",
            "Epoch 179/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7117 - loss: 0.5836 - val_accuracy: 0.7662 - val_loss: 0.5544\n",
            "Epoch 180/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7230 - loss: 0.5672 - val_accuracy: 0.7662 - val_loss: 0.5539\n",
            "Epoch 181/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7406 - loss: 0.5666 - val_accuracy: 0.7662 - val_loss: 0.5534\n",
            "Epoch 182/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7432 - loss: 0.5549 - val_accuracy: 0.7662 - val_loss: 0.5530\n",
            "Epoch 183/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.5407 - val_accuracy: 0.7662 - val_loss: 0.5526\n",
            "Epoch 184/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.5479 - val_accuracy: 0.7662 - val_loss: 0.5521\n",
            "Epoch 185/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.5602 - val_accuracy: 0.7662 - val_loss: 0.5516\n",
            "Epoch 186/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7294 - loss: 0.5683 - val_accuracy: 0.7662 - val_loss: 0.5512\n",
            "Epoch 187/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.5633 - val_accuracy: 0.7662 - val_loss: 0.5508\n",
            "Epoch 188/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7342 - loss: 0.5734 - val_accuracy: 0.7662 - val_loss: 0.5504\n",
            "Epoch 189/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 0.5358 - val_accuracy: 0.7662 - val_loss: 0.5499\n",
            "Epoch 190/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7133 - loss: 0.5732 - val_accuracy: 0.7662 - val_loss: 0.5495\n",
            "Epoch 191/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7203 - loss: 0.5683 - val_accuracy: 0.7662 - val_loss: 0.5491\n",
            "Epoch 192/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.5357 - val_accuracy: 0.7662 - val_loss: 0.5487\n",
            "Epoch 193/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7348 - loss: 0.5609 - val_accuracy: 0.7662 - val_loss: 0.5483\n",
            "Epoch 194/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7556 - loss: 0.5494 - val_accuracy: 0.7662 - val_loss: 0.5478\n",
            "Epoch 195/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7363 - loss: 0.5626 - val_accuracy: 0.7662 - val_loss: 0.5475\n",
            "Epoch 196/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.5644 - val_accuracy: 0.7662 - val_loss: 0.5470\n",
            "Epoch 197/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.5545 - val_accuracy: 0.7662 - val_loss: 0.5466\n",
            "Epoch 198/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7735 - loss: 0.5304 - val_accuracy: 0.7597 - val_loss: 0.5463\n",
            "Epoch 199/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7413 - loss: 0.5597 - val_accuracy: 0.7597 - val_loss: 0.5458\n",
            "Epoch 200/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7526 - loss: 0.5645 - val_accuracy: 0.7597 - val_loss: 0.5455\n",
            "Epoch 201/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7460 - loss: 0.5493 - val_accuracy: 0.7597 - val_loss: 0.5451\n",
            "Epoch 202/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7591 - loss: 0.5544 - val_accuracy: 0.7597 - val_loss: 0.5447\n",
            "Epoch 203/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7583 - loss: 0.5625 - val_accuracy: 0.7597 - val_loss: 0.5443\n",
            "Epoch 204/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.5457 - val_accuracy: 0.7597 - val_loss: 0.5439\n",
            "Epoch 205/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.5517 - val_accuracy: 0.7597 - val_loss: 0.5435\n",
            "Epoch 206/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7621 - loss: 0.5452 - val_accuracy: 0.7597 - val_loss: 0.5431\n",
            "Epoch 207/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7638 - loss: 0.5349 - val_accuracy: 0.7597 - val_loss: 0.5427\n",
            "Epoch 208/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7737 - loss: 0.5301 - val_accuracy: 0.7597 - val_loss: 0.5424\n",
            "Epoch 209/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7525 - loss: 0.5393 - val_accuracy: 0.7597 - val_loss: 0.5420\n",
            "Epoch 210/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.5198 - val_accuracy: 0.7597 - val_loss: 0.5416\n",
            "Epoch 211/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7643 - loss: 0.5134 - val_accuracy: 0.7597 - val_loss: 0.5412\n",
            "Epoch 212/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7683 - loss: 0.5411 - val_accuracy: 0.7597 - val_loss: 0.5409\n",
            "Epoch 213/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7518 - loss: 0.5558 - val_accuracy: 0.7597 - val_loss: 0.5405\n",
            "Epoch 214/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7376 - loss: 0.5480 - val_accuracy: 0.7597 - val_loss: 0.5401\n",
            "Epoch 215/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7745 - loss: 0.5275 - val_accuracy: 0.7597 - val_loss: 0.5398\n",
            "Epoch 216/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7242 - loss: 0.5735 - val_accuracy: 0.7597 - val_loss: 0.5394\n",
            "Epoch 217/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7268 - loss: 0.5661 - val_accuracy: 0.7597 - val_loss: 0.5390\n",
            "Epoch 218/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7461 - loss: 0.5428 - val_accuracy: 0.7597 - val_loss: 0.5387\n",
            "Epoch 219/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7416 - loss: 0.5376 - val_accuracy: 0.7597 - val_loss: 0.5383\n",
            "Epoch 220/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7544 - loss: 0.5357 - val_accuracy: 0.7597 - val_loss: 0.5380\n",
            "Epoch 221/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7460 - loss: 0.5412 - val_accuracy: 0.7597 - val_loss: 0.5376\n",
            "Epoch 222/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7587 - loss: 0.5569 - val_accuracy: 0.7597 - val_loss: 0.5373\n",
            "Epoch 223/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7548 - loss: 0.5291 - val_accuracy: 0.7597 - val_loss: 0.5370\n",
            "Epoch 224/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7429 - loss: 0.5514 - val_accuracy: 0.7597 - val_loss: 0.5366\n",
            "Epoch 225/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7574 - loss: 0.5272 - val_accuracy: 0.7597 - val_loss: 0.5363\n",
            "Epoch 226/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7668 - loss: 0.5326 - val_accuracy: 0.7597 - val_loss: 0.5360\n",
            "Epoch 227/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7593 - loss: 0.5314 - val_accuracy: 0.7597 - val_loss: 0.5356\n",
            "Epoch 228/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.5555 - val_accuracy: 0.7597 - val_loss: 0.5353\n",
            "Epoch 229/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.5529 - val_accuracy: 0.7597 - val_loss: 0.5350\n",
            "Epoch 230/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7140 - loss: 0.5594 - val_accuracy: 0.7597 - val_loss: 0.5346\n",
            "Epoch 231/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7246 - loss: 0.5604 - val_accuracy: 0.7532 - val_loss: 0.5343\n",
            "Epoch 232/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.5507 - val_accuracy: 0.7532 - val_loss: 0.5340\n",
            "Epoch 233/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7517 - loss: 0.5350 - val_accuracy: 0.7532 - val_loss: 0.5337\n",
            "Epoch 234/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7534 - loss: 0.5312 - val_accuracy: 0.7532 - val_loss: 0.5334\n",
            "Epoch 235/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7416 - loss: 0.5357 - val_accuracy: 0.7532 - val_loss: 0.5331\n",
            "Epoch 236/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.5394 - val_accuracy: 0.7532 - val_loss: 0.5327\n",
            "Epoch 237/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.5244 - val_accuracy: 0.7532 - val_loss: 0.5324\n",
            "Epoch 238/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.5168 - val_accuracy: 0.7532 - val_loss: 0.5321\n",
            "Epoch 239/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7724 - loss: 0.5290 - val_accuracy: 0.7532 - val_loss: 0.5318\n",
            "Epoch 240/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.5499 - val_accuracy: 0.7532 - val_loss: 0.5315\n",
            "Epoch 241/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7551 - loss: 0.5394 - val_accuracy: 0.7532 - val_loss: 0.5312\n",
            "Epoch 242/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7344 - loss: 0.5598 - val_accuracy: 0.7597 - val_loss: 0.5309\n",
            "Epoch 243/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7767 - loss: 0.5283 - val_accuracy: 0.7597 - val_loss: 0.5306\n",
            "Epoch 244/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7710 - loss: 0.5316 - val_accuracy: 0.7597 - val_loss: 0.5303\n",
            "Epoch 245/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.5352 - val_accuracy: 0.7597 - val_loss: 0.5300\n",
            "Epoch 246/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7602 - loss: 0.5349 - val_accuracy: 0.7597 - val_loss: 0.5298\n",
            "Epoch 247/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7540 - loss: 0.5346 - val_accuracy: 0.7597 - val_loss: 0.5295\n",
            "Epoch 248/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.5268 - val_accuracy: 0.7597 - val_loss: 0.5292\n",
            "Epoch 249/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7637 - loss: 0.5262 - val_accuracy: 0.7597 - val_loss: 0.5289\n",
            "Epoch 250/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7427 - loss: 0.5406 - val_accuracy: 0.7597 - val_loss: 0.5286\n",
            "Epoch 251/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.5058 - val_accuracy: 0.7597 - val_loss: 0.5284\n",
            "Epoch 252/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7612 - loss: 0.5310 - val_accuracy: 0.7597 - val_loss: 0.5281\n",
            "Epoch 253/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7888 - loss: 0.5247 - val_accuracy: 0.7597 - val_loss: 0.5278\n",
            "Epoch 254/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7228 - loss: 0.5596 - val_accuracy: 0.7532 - val_loss: 0.5275\n",
            "Epoch 255/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.5503 - val_accuracy: 0.7532 - val_loss: 0.5273\n",
            "Epoch 256/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.5136 - val_accuracy: 0.7532 - val_loss: 0.5270\n",
            "Epoch 257/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.5220 - val_accuracy: 0.7532 - val_loss: 0.5268\n",
            "Epoch 258/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7462 - loss: 0.5501 - val_accuracy: 0.7532 - val_loss: 0.5265\n",
            "Epoch 259/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7710 - loss: 0.5228 - val_accuracy: 0.7532 - val_loss: 0.5262\n",
            "Epoch 260/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.5220 - val_accuracy: 0.7532 - val_loss: 0.5260\n",
            "Epoch 261/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 0.5398 - val_accuracy: 0.7532 - val_loss: 0.5257\n",
            "Epoch 262/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7555 - loss: 0.5173 - val_accuracy: 0.7532 - val_loss: 0.5255\n",
            "Epoch 263/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7727 - loss: 0.5193 - val_accuracy: 0.7532 - val_loss: 0.5252\n",
            "Epoch 264/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7628 - loss: 0.5213 - val_accuracy: 0.7532 - val_loss: 0.5249\n",
            "Epoch 265/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7809 - loss: 0.5021 - val_accuracy: 0.7532 - val_loss: 0.5247\n",
            "Epoch 266/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7365 - loss: 0.5481 - val_accuracy: 0.7532 - val_loss: 0.5244\n",
            "Epoch 267/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7375 - loss: 0.5335 - val_accuracy: 0.7532 - val_loss: 0.5242\n",
            "Epoch 268/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7664 - loss: 0.5217 - val_accuracy: 0.7532 - val_loss: 0.5240\n",
            "Epoch 269/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7636 - loss: 0.5247 - val_accuracy: 0.7532 - val_loss: 0.5237\n",
            "Epoch 270/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7691 - loss: 0.5215 - val_accuracy: 0.7532 - val_loss: 0.5235\n",
            "Epoch 271/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7658 - loss: 0.5284 - val_accuracy: 0.7532 - val_loss: 0.5233\n",
            "Epoch 272/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7807 - loss: 0.5133 - val_accuracy: 0.7468 - val_loss: 0.5230\n",
            "Epoch 273/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7754 - loss: 0.5197 - val_accuracy: 0.7468 - val_loss: 0.5228\n",
            "Epoch 274/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7467 - loss: 0.5349 - val_accuracy: 0.7468 - val_loss: 0.5226\n",
            "Epoch 275/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7628 - loss: 0.5155 - val_accuracy: 0.7468 - val_loss: 0.5224\n",
            "Epoch 276/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7560 - loss: 0.5204 - val_accuracy: 0.7468 - val_loss: 0.5221\n",
            "Epoch 277/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7538 - loss: 0.5336 - val_accuracy: 0.7468 - val_loss: 0.5219\n",
            "Epoch 278/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7583 - loss: 0.5336 - val_accuracy: 0.7468 - val_loss: 0.5217\n",
            "Epoch 279/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7835 - loss: 0.5137 - val_accuracy: 0.7468 - val_loss: 0.5214\n",
            "Epoch 280/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7611 - loss: 0.5281 - val_accuracy: 0.7468 - val_loss: 0.5212\n",
            "Epoch 281/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.5374 - val_accuracy: 0.7468 - val_loss: 0.5210\n",
            "Epoch 282/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7566 - loss: 0.5366 - val_accuracy: 0.7468 - val_loss: 0.5208\n",
            "Epoch 283/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7776 - loss: 0.5174 - val_accuracy: 0.7468 - val_loss: 0.5206\n",
            "Epoch 284/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7502 - loss: 0.5212 - val_accuracy: 0.7532 - val_loss: 0.5204\n",
            "Epoch 285/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.5508 - val_accuracy: 0.7532 - val_loss: 0.5201\n",
            "Epoch 286/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7322 - loss: 0.5367 - val_accuracy: 0.7532 - val_loss: 0.5199\n",
            "Epoch 287/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.5275 - val_accuracy: 0.7532 - val_loss: 0.5197\n",
            "Epoch 288/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7290 - loss: 0.5307 - val_accuracy: 0.7532 - val_loss: 0.5195\n",
            "Epoch 289/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.5282 - val_accuracy: 0.7532 - val_loss: 0.5193\n",
            "Epoch 290/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.5194 - val_accuracy: 0.7532 - val_loss: 0.5191\n",
            "Epoch 291/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7373 - loss: 0.5331 - val_accuracy: 0.7532 - val_loss: 0.5189\n",
            "Epoch 292/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.5468 - val_accuracy: 0.7532 - val_loss: 0.5187\n",
            "Epoch 293/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7766 - loss: 0.5069 - val_accuracy: 0.7532 - val_loss: 0.5185\n",
            "Epoch 294/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7588 - loss: 0.5418 - val_accuracy: 0.7532 - val_loss: 0.5183\n",
            "Epoch 295/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7308 - loss: 0.5414 - val_accuracy: 0.7532 - val_loss: 0.5181\n",
            "Epoch 296/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7376 - loss: 0.5287 - val_accuracy: 0.7532 - val_loss: 0.5179\n",
            "Epoch 297/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7694 - loss: 0.5262 - val_accuracy: 0.7532 - val_loss: 0.5177\n",
            "Epoch 298/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7454 - loss: 0.5218 - val_accuracy: 0.7532 - val_loss: 0.5175\n",
            "Epoch 299/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 0.5381 - val_accuracy: 0.7532 - val_loss: 0.5173\n",
            "Epoch 300/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7307 - loss: 0.5253 - val_accuracy: 0.7532 - val_loss: 0.5171\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7346 - loss: 0.5181 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Test Accuracy: 0.7532\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-Diabetic       0.78      0.86      0.82        99\n",
            "    Diabetic       0.69      0.56      0.62        55\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.71      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unable to synchronously create dataset (name already exists)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-349930294fe3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"diabetes_ann_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0, fill_time)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mdset_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"
          ]
        }
      ]
    }
  ]
}